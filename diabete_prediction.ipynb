{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdd195e",
   "metadata": {},
   "source": [
    "For this project, I will show the process of building a model to predict readmission for diabetes patients. And the process can be divided into 5 parts.\n",
    "\n",
    "data exploration\n",
    "\n",
    "feature engineerin\n",
    "\n",
    "building training/validation/test samples\n",
    "\n",
    "modelling\n",
    "\n",
    "model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e33506",
   "metadata": {},
   "source": [
    "dara source:https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea1cf5",
   "metadata": {},
   "source": [
    "### check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f42e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of samples:',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae65fb",
   "metadata": {},
   "source": [
    "This data have more than 100000 items and 51 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b85e51",
   "metadata": {},
   "source": [
    "Then check the values of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257cb82",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f07a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing values\n",
    "df = df.replace(\"?\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows for each type\n",
    "df.groupby('readmitted').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fb701",
   "metadata": {},
   "source": [
    "This is an imbalanced dataset, and we'll deal with that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa38373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the patient's discharge directions\n",
    "df.groupby('discharge_disposition_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f23862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove meaningless data\n",
    "df = df.loc[~df.discharge_disposition_id.isin([11,13,14,19,20,21])]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4b58c",
   "metadata": {},
   "source": [
    "You can see many string variables. You can see the meaning of ids_mapping.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ee225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the fuction for checking the value of features\n",
    "for c in list(df.columns):\n",
    "    \n",
    "    # get a list of unique values\n",
    "    n = df[c].unique()\n",
    "    \n",
    "    # if number of unique values is less than 30, print the values. Otherwise print the number of unique values\n",
    "    if len(n)<30:\n",
    "        print(c)\n",
    "        print(n)\n",
    "    else:\n",
    "        print(c + ': ' +str(len(n)) + ' unique values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069d0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9683f76",
   "metadata": {},
   "source": [
    "Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ? with nan\n",
    "df = df.replace('?',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d96f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = ['time_in_hospital','num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "       'number_outpatient', 'number_emergency', 'number_inpatient','number_diagnoses']\n",
    "df[num_list].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = ['race', 'gender', \n",
    "       'max_glu_serum', 'A1Cresult',\n",
    "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "       'metformin-pioglitazone', 'change', 'diabetesMed','payer_code','medical_specialty']\n",
    "df[cat_list].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325faf6",
   "metadata": {},
   "source": [
    "deal with features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].fillna('UNK')\n",
    "# too many missing values, so drop them\n",
    "df = df.drop(labels=['medical_specialty','payer_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8238629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3473354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmentation feature\n",
    "df[['age', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7630ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('age').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3da396",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_id = {'[0-10)':0, \n",
    "          '[10-20)':10, \n",
    "          '[20-30)':20, \n",
    "          '[30-40)':30, \n",
    "          '[40-50)':40, \n",
    "          '[50-60)':50,\n",
    "          '[60-70)':60, \n",
    "          '[70-80)':70, \n",
    "          '[80-90)':80, \n",
    "          '[90-100)':90}\n",
    "df['age_group'] = df.age.replace(age_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d31db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#too many missing values\n",
    "df = df.drop(labels=['age','weight'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755599d9",
   "metadata": {},
   "source": [
    "Considering the clinical information, these data are presented without clinical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1637d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['examide' , 'citoglipton','encounter_id','patient_nbr']  \n",
    "df.drop(drop_list,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missiing value\n",
    "diag_list = ['diag_1','diag_2','diag_3']\n",
    "\n",
    "for col in diag_list:\n",
    "    df[col].fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# feature eigineering for dig1,dig2,dig3\n",
    "def transformFunc(value):\n",
    "    value = re.sub(\"V[0-9]*\", \"0\", value) # V \n",
    "    value = re.sub(\"E[0-9]*\", \"0\", value) # E \n",
    "    value = re.sub('NaN', \"-1\", value) # Nan \n",
    "    return value\n",
    "\n",
    "def transformCategory(value):\n",
    "    if value>=390 and value<=459 or value==785:\n",
    "        category = 'Circulatory'\n",
    "    elif value>=460 and value<=519 or value==786:\n",
    "        category = 'Respiratory'\n",
    "    elif value>=520 and value<=579 or value==787:\n",
    "        category = 'Digestive'\n",
    "    elif value==250:\n",
    "        category = 'Diabetes'\n",
    "    elif value>=800 and value<=999:\n",
    "        category = 'Injury'          \n",
    "    elif value>=710 and value<=739:\n",
    "        category = 'Musculoskeletal'   \n",
    "    elif value>=580 and value<=629 or value==788:\n",
    "        category = 'Genitourinary'\n",
    "    elif value>=140 and value<=239 :\n",
    "        category = 'Neoplasms'\n",
    "    elif value==-1:\n",
    "        category = 'NAN'\n",
    "    else :\n",
    "        category = 'Other'\n",
    "    return category\n",
    "\n",
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformFunc)\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding for the 24 Drug \n",
    "drugs = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone',\n",
    "        'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone',\n",
    "        'metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "\n",
    "for col in drugs:\n",
    "    df[col] = df[col].replace(['No','Steady','Up','Down'],[0,1,1,1])\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with A1Cresult and max_glu_serum\n",
    "df['A1Cresult'] = df['A1Cresult'].replace(['>7','>8','Norm','None'],[1,1,0,-99])\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace(['>200','>300','Norm','None'],[1,1,0,-99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(df.columns)[:10]].head()\n",
    "df[list(df.columns)[10:20]].head()\n",
    "df[list(df.columns)[20:30]].head()\n",
    "df[list(df.columns)[30:40]].head()\n",
    "df[list(df.columns)[40:]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1d0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de79462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "one_hot_data = pd.get_dummies(df, columns=['race'], prefix=[\"enc\"])\n",
    "columns_ids = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "one_hot_data[columns_ids] = df[columns_ids].astype('str')\n",
    "one_hot_data = pd.get_dummies(one_hot_data, columns=columns_ids)\n",
    "data=one_hot_data.copy()\n",
    "data.readmitted = [1 if each=='<30' else 0 for each in data.readmitted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the label feature\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in diag_list:\n",
    "    label_enc = LabelEncoder()\n",
    "    data[col] = label_enc.fit_transform(data[col])\n",
    "    \n",
    "    \n",
    "binary = ['change', 'diabetesMed', 'gender']\n",
    "from category_encoders import BinaryEncoder\n",
    "binary_enc = BinaryEncoder(cols=binary)\n",
    "binary_enc.fit_transform(data)\n",
    "data = binary_enc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14993763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training/validation/test samples\n",
    "X = data.drop(columns=\"readmitted\", axis=1)\n",
    "Y = data.readmitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f724d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with imblanced data by using SMOTE function\n",
    "from imblearn.over_sampling import SMOTE\n",
    "column_name = X_train.columns\n",
    "X_train,y_train = SMOTE().fit_sample(X_train,y_train)\n",
    "X_train = pd.DataFrame(X_train,columns = column_name)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generic code that outputs the modeling results comes from Github\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score,recall_score,mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    fscore = f1_score(y_actual,(y_pred > thresh) )\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('fscore:%.3f'%fscore)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision,fscore, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca70d6",
   "metadata": {},
   "source": [
    "SVM modelling and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def run_SVM(X_train,X_test):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_pred_prob = svm.decision_function(X_test)\n",
    "    svm_accuracy = sklearn.metrics.accuracy_score(y_test, svm_pred)\n",
    "    print(\"Accuracy : \",svm_accuracy)\n",
    "    k = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test,svm_pred))\n",
    "    print(k)\n",
    "    \n",
    "    \n",
    "    predictions = svm.predict(X_train)\n",
    "    train_score = round(accuracy_score(y_train, predictions), 3)\n",
    "    cm_train = cm(y_train, predictions)\n",
    "\n",
    "    predictions = svm.predict(X_test)\n",
    "    val_score = round(accuracy_score(y_test, predictions), 3)\n",
    "    cm_val = cm(y_test, predictions)\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \n",
    "    sns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\n",
    "    ax1.set_xlabel('Predicted Values')\n",
    "    ax1.set_ylabel('Actual Values')\n",
    "    ax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\n",
    "    sns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\n",
    "    ax2.set_xlabel('Predicted Values')\n",
    "    ax2.set_ylabel('Actual Values')\n",
    "    ax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return svm_pred_prob\n",
    "\n",
    "SVM_prob = run_SVM(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15613605",
   "metadata": {},
   "source": [
    "LR modelling and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28209123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def run_lg(X_train,X_test):\n",
    "    lg = LogisticRegression(C=1)\n",
    "    lg.fit(X_train,y_train)\n",
    "    lg_pred = lg.predict(X_test)\n",
    "    lg_pred_prob = lg.predict_proba(X_test)[:,1]\n",
    "    k = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test,lg_pred))\n",
    "    lg_accuracy = sklearn.metrics.accuracy_score(y_test, lg_pred)\n",
    "    print(\"Accuracy : \",lg_accuracy)\n",
    "    k = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test,lg_pred))\n",
    "    print(k)\n",
    "    \n",
    "    \n",
    "    predictions = lg.predict(X_train)\n",
    "    train_score = round(accuracy_score(y_train, predictions), 3)\n",
    "    cm_train = cm(y_train, predictions)\n",
    "\n",
    "    predictions = lg.predict(X_test)\n",
    "    val_score = round(accuracy_score(y_test, predictions), 3)\n",
    "    cm_val = cm(y_test, predictions)\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \n",
    "    sns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\n",
    "    ax1.set_xlabel('Predicted Values')\n",
    "    ax1.set_ylabel('Actual Values')\n",
    "    ax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\n",
    "    sns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\n",
    "    ax2.set_xlabel('Predicted Values')\n",
    "    ax2.set_ylabel('Actual Values')\n",
    "    ax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return lg_pred_prob\n",
    "\n",
    "lg_prob = run_lg(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgboost modelling and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "def run_xgb(X_train,X_test):\n",
    "    xgb= xgboost.XGBClassifier(n_estimators =200,max_depth =8,learning_rate = 0.01)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    xgb_pred = xgb.predict(X_test) \n",
    "    xgb_pred_prob = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "    xgb_accuracy = sklearn.metrics.accuracy_score(y_test, xgb_pred)\n",
    "    xgb_roc = sklearn.metrics.roc_auc_score(y_test, xgb_pred_prob)\n",
    "    print(\"Accuracy : \",xgb_accuracy)\n",
    "    print(\"ROC Score : \",xgb_roc)\n",
    "    k = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test,xgb_pred))\n",
    "    print(k)\n",
    "    \n",
    "    \n",
    "    from xgboost import plot_importance\n",
    "    plot_importance(xgb,max_num_features=10)\n",
    "    plt.savefig(\"./xgboost.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return xgb_pred_prob\n",
    "xgb_prob = run_xgb(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lightgbm modelling and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad78940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "\n",
    "def run_lgb(X_train,X_test):\n",
    "    lgb= LGBMClassifier(num_leaves =63,max_depth =10,learning_rate = 0.001)\n",
    "\n",
    "    lgb.fit(X_train, y_train)\n",
    "\n",
    "    lgb_pred = lgb.predict(X_test) \n",
    "    lgb_pred_prob = lgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "    lgb_accuracy = sklearn.metrics.accuracy_score(y_test, lgb_pred)\n",
    "    lgb_roc = sklearn.metrics.roc_auc_score(y_test, lgb_pred_prob)\n",
    "    print(\"Accuracy : \",lgb_accuracy)\n",
    "    print(\"ROC Score : \",lgb_roc)\n",
    "    k = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test,lgb_pred))\n",
    "    print(k)\n",
    "    \n",
    "#     predictions = lgb.predict(X_train)\n",
    "#     train_score = round(accuracy_score(y_train, predictions), 3)\n",
    "#     cm_train = cm(y_train, predictions)\n",
    "\n",
    "#     predictions = lgb.predict(X_test)\n",
    "#     val_score = round(accuracy_score(y_test, predictions), 3)\n",
    "#     cm_val = cm(y_test, predictions)\n",
    "#     print(accuracy_score(y_test, predictions))\n",
    "\n",
    "#     fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \n",
    "#     sns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\n",
    "#     ax1.set_xlabel('Predicted Values')\n",
    "#     ax1.set_ylabel('Actual Values')\n",
    "#     ax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\n",
    "#     sns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\n",
    "#     ax2.set_xlabel('Predicted Values')\n",
    "#     ax2.set_ylabel('Actual Values')\n",
    "#     ax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\n",
    "#     plt.show()\n",
    "\n",
    "#     print(type(cm_train))\n",
    "    \n",
    "#     ax=lightgbm.plot_importance(lgb, max_num_features=10)\n",
    "#     plt.show()\n",
    "#     plt.savefig(\"./lightgbm1.jpg\")\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(30,12))\n",
    "    lightgbm.plot_importance(lgb, max_num_features=10)\n",
    "    plt.savefig(\"./lightgbm2.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return lgb_pred_prob\n",
    "lgb_prob = run_lgb(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = {\n",
    "  'SVM_prob': SVM_prob,\n",
    "  'lg_prob': lg_prob,\n",
    "  'xgb_prob': xgb_prob,\n",
    "  'lgb_prob': lgb_prob,\n",
    "    \n",
    "  }  \n",
    "models=pd.DataFrame(merge)\n",
    "\n",
    "w=[0.2,0.1,0.35,0.35]\n",
    "w_average = [1/5,1/5,1/5,1/5]\n",
    "direct=np.dot(models.values,w)\n",
    "\n",
    "stacking_pred =[1 if i>0.5 else 0 for i in direct] \n",
    "nn_accuracy = sklearn.metrics.accuracy_score(y_test, stacking_pred)\n",
    "nn_roc = sklearn.metrics.roc_auc_score(y_test, direct)\n",
    "print(\"Accuracy : \",nn_accuracy)\n",
    "print(\"ROC Score : \",nn_roc)\n",
    "k = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test,stacking_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
